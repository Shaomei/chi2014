{\rtf1\ansi\ansicpg1252\cocoartf1187\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww12860\viewh14920\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 1. Photograph: Add stats about how many pictures have captions. There is no way to tell the difference between "personal" pictures and "app-generated" pictures, also, even the app-generated ones, people sometimes edit the pre-generated caption (taptapsee) \
\
We didn't look at the content of the pictures also because of privacy concerns.. using caption is just a way for us to access the content of pictures. Sighted users also have a lot of auto-generated pictures, but somehow they didn't stick out as most representative words.\
\
\
2. TapTapSee sample -  One reason we use this sample is the demographics diversity in the VoiceOver sample (people may have different levels of visual impairment, not totally blind), so we thought it would be very interesting to look at a smaller subset but it turned out didn't add much and could be removed. We will use the additional space for more discussion on the ethical issues.\
\
3. Auto-detection disability users and related ethical issues. The standardization of accessibility technologies make it possible for websites to detect whether their visitors are visually-impaired and serve content accordingly. Amazon has been the leading service on this and they will re-directed visually-impaired users to Amazon/access, which provides much less pictures and more/bigger text. It has been very well received by the visually impaired community (in our interviews with them). Visually impaired users know that website are detecting their device. Our study is highly aggregated and anonymized, and all the analysis were done on Facebook servers, so it is compatible with FB's TOS and privacy policies.\
\
\
4 (?). We have also been interviewing visually impaired users about their experience on social media, but this work is still on-going and we are contiously learning new things.\
\
5. Will definitely fix all the typos and grammatical problems.\
\
6. Keywords: the methods we used tried to balance the volumn and the uniqueness. But can also include the % of status messages containing at least one of these keywords. List the keywords selected for the iPhone users groups. \
\
7. The count of actions during the 3 weeks and 1 week feedback: it's in the y-axis of Figure 1.\
\
8. Normal-distribution\'85? We used CDF and see similar trends. Could replace the bar charts with a series of CDF curves.\
\
9. No difference: we are just saying there is no difference in the specific metrics that we have looked at. \
\
10. We didn't say that visually impaired users have their network-size changed over time, what we are trying to say is that if we control on how long a person has been on Facebook, among people who have been around longer, visually impaired users did have a smaller network than the average users, but among people who joined in the past couple of years, we don't see the difference. \
\
11. We identify people from the first period (June 15 to July 15), and observe their behavior in the second period (August 4 to August 25). The reason to used the two different period of time is that we want to filter and clean the sample based on the overall pattern in a month. \
\
12. The longitual view is done by comparing people who are at different stages of their Facebook life.\
\
13. impact of the findings on future research and designs\
\
14. peachtree/tunein: what photos are shared and how?\
\
15. how many people using voiceover more than 3 times per month, but for less than 50% of their visits to Facebook?\
\
16. Discussion on collecting big data about how people with disabilities use the internet.\
\
}